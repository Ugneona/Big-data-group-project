{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_timestamp, count, radians, sin, cos, sqrt, asin, lag, sum as _sum, round as spark_round, count_distinct, count\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DoubleType\n",
    "import os\n",
    "import findspark\n",
    "import folium\n",
    "import pandas\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Staring up pyspark, based on the individual setup\n",
    "# os.environ[\"SPARK_LOCAL_IP\"] = \"IP\"\n",
    "# os.environ[\"PYSPARK_PYTHON\"] = r\"C:\\.....\\pyspark_env\\python.exe\"\n",
    "# os.environ[\"PYSPARK_DRIVER_PYTHON\"] = r\"C:\\....\\pyspark_env\\python.exe\"\n",
    "\n",
    "findspark.init()\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[8]\")\n",
    "    .appName(\"PortDetectionTask\")\n",
    "    .getOrCreate()\n",
    "    )\n",
    "\n",
    "# Read ship data\n",
    "df = spark.read.csv(\"aisdk-2025-04-20.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Define functions used for this task\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    Takes a dataframe, returns a cleaned one.\n",
    "\n",
    "    Only take useful columns, drop NA values, cast to appopriate data types.\n",
    "    Remove ships with non-standart coordinate types, helicopters.\n",
    "    '''\n",
    "    # Some standard cleaning\n",
    "    df_clean = (\n",
    "        df.select(\"MMSI\", \"# Timestamp\", \"Latitude\", \"Longitude\", \"SOG\", \"Ship type\")\n",
    "        .dropna(subset=[\"MMSI\", \"# Timestamp\", \"Latitude\", \"Longitude\", \"SOG\"])\n",
    "        .withColumn(\"Latitude\", col(\"Latitude\").cast(DoubleType()))\n",
    "        .withColumn(\"Longitude\", col(\"Longitude\").cast(DoubleType()))\n",
    "        .withColumn(\"SOG\", col(\"SOG\").cast(DoubleType()))\n",
    "        .withColumn(\"Timestamp\", to_timestamp(col(\"# Timestamp\"), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "    )\n",
    "\n",
    "    # Cleaning up the ships with weird coordinates\n",
    "    df_clean = df_clean.filter(\n",
    "        (col(\"Latitude\").between(-90, 90)) &\n",
    "        (col(\"Longitude\").between(-180, 180))\n",
    "    )\n",
    "\n",
    "    # Remove search and rescue helicopters from the analysis\n",
    "    df_clean = df_clean.filter(\n",
    "        col(\"Ship type\") != \"SAR\"\n",
    "    )\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def filter_moving_ships(df_clean, sog_filter=0.5, sog_number_filter=5, total_distance_filter=10.0):\n",
    "    '''\n",
    "    Takes a dataframe and filtering parameters, returns a filtered one of stationary vessels.\n",
    "\n",
    "    Remove vessels based on these two conditions:\n",
    "        1. Moving vessels that send speed of 0.5 or higher for more than 5 times.\n",
    "        2. Ones that have traveled for more than 10 kilometers in the given day.\n",
    "    '''\n",
    "    # Ships that are sending SOG >= (0.5) for more than (5) time are excluded.\n",
    "    low_speed_df = df_clean.filter(col(\"SOG\") < sog_filter)\n",
    "\n",
    "    dwelling_ships = (\n",
    "        low_speed_df.groupBy(\"MMSI\")\n",
    "                    .agg(count(\"*\").alias(\"low_speed_msgs\"))\n",
    "                    .filter(col(\"low_speed_msgs\") >= sog_number_filter)\n",
    "    )\n",
    "\n",
    "    slow_moving_df = (\n",
    "        low_speed_df.join(dwelling_ships, on=\"MMSI\", how=\"inner\")\n",
    "    )\n",
    "\n",
    "    # Display the slow ships\n",
    "    total_slow_moving_ships = slow_moving_df.select(\"MMSI\").distinct().count()\n",
    "    print(f\"Total stationary/drifting ships: {total_slow_moving_ships}\")\n",
    "\n",
    "    slow_moving_df.show(5, truncate=False)\n",
    "\n",
    "    # Now distance filtering is performed\n",
    "    low_speed_filtered = slow_moving_df\n",
    "\n",
    "    # Window.partition function for previous coordinates\n",
    "    windowSpec = Window.partitionBy(\"MMSI\").orderBy(\"Timestamp\")\n",
    "\n",
    "    df_distance = (\n",
    "        low_speed_filtered.withColumn(\"prev_lat\", lag(\"Latitude\").over(windowSpec))\n",
    "                        .withColumn(\"prev_lon\", lag(\"Longitude\").over(windowSpec))\n",
    "                        .dropna(subset=[\"prev_lat\", \"prev_lon\"])\n",
    "    )\n",
    "\n",
    "    # Convert to radians for distance calculation\n",
    "    df_distance = (\n",
    "        df_distance.withColumn(\"lat1\", radians(col(\"prev_lat\")))\n",
    "                .withColumn(\"lon1\", radians(col(\"prev_lon\")))\n",
    "                .withColumn(\"lat2\", radians(col(\"Latitude\")))\n",
    "                .withColumn(\"lon2\", radians(col(\"Longitude\")))\n",
    "    )\n",
    "\n",
    "\n",
    "    # Calculate haversine distance in pyspark SQL\n",
    "    df_distance = (\n",
    "        df_distance.withColumn(\"dlat\", col(\"lat2\") - col(\"lat1\"))\n",
    "                .withColumn(\"dlon\", col(\"lon2\") - col(\"lon1\"))\n",
    "                .withColumn(\"a\", sin(col(\"dlat\") / 2) ** 2 +\n",
    "                                    cos(col(\"lat1\")) * cos(col(\"lat2\")) *\n",
    "                                    sin(col(\"dlon\") / 2) ** 2)\n",
    "                .withColumn(\"c\", 2 * asin(sqrt(col(\"a\"))))\n",
    "                .withColumn(\"segment_km\", col(\"c\") * 6371) \n",
    "    )\n",
    "\n",
    "    # Total distance traveled by MMSI\n",
    "    total_distance = (\n",
    "        df_distance.groupBy(\"MMSI\")\n",
    "                .agg(_sum(\"segment_km\").alias(\"total_distance_km\"))\n",
    "    )\n",
    "\n",
    "    # Filter ships that traveled more than (10)km\n",
    "    stationary_ships = total_distance.filter(col(\"total_distance_km\") < total_distance_filter)\n",
    "\n",
    "    # Join the filtered low speed ships and the filtered small distance traveled ships\n",
    "    df_filtered = low_speed_filtered.join(stationary_ships, on=\"MMSI\", how=\"inner\")\n",
    "\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c5fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stationary/drifting ships: 3078\n",
      "+---------+-------------------+---------+---------+---+---------+-------------------+--------------+\n",
      "|MMSI     |# Timestamp        |Latitude |Longitude|SOG|Ship type|Timestamp          |low_speed_msgs|\n",
      "+---------+-------------------+---------+---------+---+---------+-------------------+--------------+\n",
      "|219024194|20/04/2025 00:00:01|54.995438|11.874798|0.0|Undefined|2025-04-20 00:00:01|11417         |\n",
      "|246389000|20/04/2025 00:00:02|54.994648|11.87351 |0.0|Undefined|2025-04-20 00:00:02|15552         |\n",
      "|246389000|20/04/2025 00:00:02|54.994648|11.87351 |0.0|Undefined|2025-04-20 00:00:02|15552         |\n",
      "|257476500|20/04/2025 00:00:03|56.701   |8.21937  |0.0|Undefined|2025-04-20 00:00:03|16294         |\n",
      "|257476500|20/04/2025 00:00:03|56.701   |8.21937  |0.0|Undefined|2025-04-20 00:00:03|16294         |\n",
      "+---------+-------------------+---------+---------+---+---------+-------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total stationary/drifting ships: 2400\n",
      "+---------+-------------------+---------+---------+---+---------+-------------------+--------------+-------------------+\n",
      "|MMSI     |# Timestamp        |Latitude |Longitude|SOG|Ship type|Timestamp          |low_speed_msgs|total_distance_km  |\n",
      "+---------+-------------------+---------+---------+---+---------+-------------------+--------------+-------------------+\n",
      "|209864000|20/04/2025 18:04:38|55.424912|13.824908|0.4|Passenger|2025-04-20 18:04:38|186           |0.02772837330389764|\n",
      "|209864000|20/04/2025 18:04:49|55.424908|13.824917|0.0|Passenger|2025-04-20 18:04:49|186           |0.02772837330389764|\n",
      "|209864000|20/04/2025 18:04:58|55.424908|13.824917|0.0|Passenger|2025-04-20 18:04:58|186           |0.02772837330389764|\n",
      "|209864000|20/04/2025 18:05:07|55.42491 |13.824917|0.0|Passenger|2025-04-20 18:05:07|186           |0.02772837330389764|\n",
      "|209864000|20/04/2025 18:05:17|55.424908|13.824923|0.2|Passenger|2025-04-20 18:05:17|186           |0.02772837330389764|\n",
      "+---------+-------------------+---------+---------+---+---------+-------------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering results\n",
    "df_clean = clean_data(df)\n",
    "df_filtered = filter_moving_ships(df_clean)\n",
    "\n",
    "total_stationary_ships = df_filtered.select(\"MMSI\").distinct().count()\n",
    "print(f\"Total stationary/drifting ships: {total_stationary_ships}\")\n",
    "\n",
    "df_filtered.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62693fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|      Ship type|  count|\n",
      "+---------------+-------+\n",
      "|        Fishing|2463211|\n",
      "|          Other| 374638|\n",
      "|          Cargo| 348770|\n",
      "|       Pleasure| 346419|\n",
      "|            Tug| 274958|\n",
      "|          Pilot| 252789|\n",
      "|        Sailing| 251809|\n",
      "|      Passenger| 245374|\n",
      "|       Dredging| 190984|\n",
      "|      Undefined| 165755|\n",
      "|         Tanker| 132113|\n",
      "|       Military|  80599|\n",
      "|       Reserved|  70828|\n",
      "|            HSC|  56624|\n",
      "|    Port tender|  33997|\n",
      "|         Towing|  25141|\n",
      "|Law enforcement|  17229|\n",
      "|        Medical|   8499|\n",
      "|         Diving|   7582|\n",
      "| Anti-pollution|   2370|\n",
      "+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.groupBy(\"Ship type\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+\n",
      "|lat_bin|lon_bin|vessel_count|\n",
      "+-------+-------+------------+\n",
      "|57.59  |9.96   |56          |\n",
      "|57.12  |8.6    |44          |\n",
      "|56.7   |8.22   |43          |\n",
      "|54.38  |10.98  |40          |\n",
      "|57.72  |10.59  |34          |\n",
      "|56.13  |12.31  |28          |\n",
      "|55.06  |10.62  |22          |\n",
      "|54.81  |9.45   |21          |\n",
      "|56.41  |10.92  |21          |\n",
      "|57.06  |9.9    |19          |\n",
      "|57.49  |10.5   |18          |\n",
      "|55.1   |14.69  |18          |\n",
      "|54.85  |10.52  |17          |\n",
      "|55.33  |11.13  |16          |\n",
      "|54.67  |9.94   |16          |\n",
      "|55.47  |8.42   |16          |\n",
      "|55.69  |12.62  |16          |\n",
      "|57.49  |10.51  |15          |\n",
      "|55.19  |14.7   |15          |\n",
      "|55.59  |12.68  |14          |\n",
      "+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-------+------------+\n",
      "|lat_bin|lon_bin|vessel_count|\n",
      "+-------+-------+------------+\n",
      "|54.47  |9.04   |9           |\n",
      "|54.91  |9.6    |6           |\n",
      "|57.59  |9.95   |8           |\n",
      "|54.91  |9.89   |8           |\n",
      "|54.18  |12.1   |10          |\n",
      "+-------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bin_ships(df, filter_ships=5):\n",
    "    '''\n",
    "    Bin ships to clusters based on lattidute and longitude.\n",
    "    Grid size is approximately 0.64 x 1.11km rectangles (roughly 0.7km squared), may differ depending on latidute and longitude.\n",
    "    '''\n",
    "    # Round of the coordinates to create bins\n",
    "    binned_df = (\n",
    "        df.withColumn(\"lat_bin\", spark_round(col(\"Latitude\"), 2))\n",
    "        .withColumn(\"lon_bin\", spark_round(col(\"Longitude\"), 2))\n",
    "    )\n",
    "\n",
    "    # Assing vessel count to bins and filter small potential ports\n",
    "    port_candidates = (\n",
    "        binned_df.groupBy(\"lat_bin\", \"lon_bin\")\n",
    "                .agg(count_distinct(\"MMSI\").alias(\"vessel_count\"))\n",
    "                .filter(col(\"vessel_count\") >= filter_ships)\n",
    "    )\n",
    "    \n",
    "    # Print out the biggest ports\n",
    "    port_candidates.orderBy(col(\"vessel_count\").desc()).show(5, truncate=False)\n",
    "    \n",
    "    return port_candidates\n",
    "\n",
    "port_candidates = bin_ships(df_filtered)\n",
    "port_candidates.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e879154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_candidates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c0ae9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lat_bin    lon_bin  vessel_count\n",
      "cluster                                    \n",
      "8        55.734615  12.600000           131\n",
      "2        57.590000   9.965000            76\n",
      "5        57.462857  10.528571            68\n",
      "19       57.717500  10.587500            63\n",
      "21       54.367500  11.007500            62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simple scikit-learn clustering is used, as we have only 144 port candidates and parallel processing would not improve computing speed\n",
    "def cluster_dbscan(df, eps=0.1, min_samples=1):\n",
    "    '''\n",
    "    Create dbscan clusters based on coordinate bins, eps of 0.1 ~ 11km\n",
    "    '''\n",
    "\n",
    "    pandas_df = df.toPandas()\n",
    "    coordinates = pandas_df[['lat_bin', 'lon_bin']].values\n",
    "\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    cluster_labels = dbscan.fit_predict(coordinates)\n",
    "\n",
    "    pandas_df['cluster'] = cluster_labels\n",
    "    ports_clusters = pandas_df.groupby('cluster').agg(\n",
    "        lat_bin = ('lat_bin', 'mean'),\n",
    "        lon_bin = ('lon_bin', 'mean'),\n",
    "        vessel_count = ('vessel_count', 'sum')\n",
    "    )\n",
    "\n",
    "    print(ports_clusters.sort_values('vessel_count', ascending=False).head())\n",
    "\n",
    "    return ports_clusters\n",
    "\n",
    "ports_clusters = cluster_dbscan(port_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f495ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+\n",
      "|lat_bin_ports|lon_bin_ports|vessel_total_count|\n",
      "+-------------+-------------+------------------+\n",
      "|57.6         |10.0         |76                |\n",
      "|55.7         |12.6         |73                |\n",
      "|57.7         |10.6         |63                |\n",
      "|57.1         |8.6          |55                |\n",
      "|54.4         |11.0         |54                |\n",
      "|57.5         |10.5         |44                |\n",
      "|55.5         |8.4          |44                |\n",
      "|56.7         |8.2          |43                |\n",
      "|55.6         |12.4         |31                |\n",
      "|57.1         |9.9          |31                |\n",
      "|56.1         |12.3         |28                |\n",
      "|55.1         |14.7         |28                |\n",
      "|54.6         |11.4         |26                |\n",
      "|55.6         |12.9         |23                |\n",
      "|55.6         |12.7         |23                |\n",
      "|55.1         |10.6         |22                |\n",
      "|56.4         |10.9         |21                |\n",
      "|54.8         |9.5          |21                |\n",
      "|54.2         |12.1         |21                |\n",
      "|54.7         |9.9          |21                |\n",
      "+-------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+-------------+------------------+\n",
      "|lat_bin_ports|lon_bin_ports|vessel_total_count|\n",
      "+-------------+-------------+------------------+\n",
      "|         57.0|          8.4|                 5|\n",
      "|         56.0|         12.7|                 9|\n",
      "|         56.8|          8.9|                15|\n",
      "|         54.9|          9.6|                18|\n",
      "|         56.2|         10.2|                 7|\n",
      "+-------------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bin_ports(df):\n",
    "    '''\n",
    "    Bin ports to clusters based on lattidute and longitude.\n",
    "    Grid cell size is approximately 6.4 Ã— 11.1km rectangles (roughly 71km squared), may differ depending on latidute and longitude.\n",
    "    '''\n",
    "\n",
    "    binned_df = (\n",
    "        df.withColumn(\"lat_bin_ports\", spark_round(col(\"lat_bin\"), 1))\n",
    "        .withColumn(\"lon_bin_ports\", spark_round(col(\"lon_bin\"), 1))\n",
    "    )\n",
    "    \n",
    "    port_candidates_agg = (\n",
    "        binned_df.groupBy(\"lat_bin_ports\", \"lon_bin_ports\")\n",
    "                .agg(_sum(\"vessel_count\").alias(\"vessel_total_count\"))\n",
    "    )\n",
    "    \n",
    "    port_candidates_agg.orderBy(col(\"vessel_total_count\").desc()).show(truncate=False)\n",
    "    \n",
    "    return port_candidates_agg\n",
    "\n",
    "port_candidates_agg = bin_ports(port_candidates)\n",
    "port_candidates_agg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ebd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ports(port_candidates, map_name='port_map', to_pandas=True):\n",
    "    # Transfer pyspark to pandas dataframe\n",
    "    if to_pandas == True:\n",
    "        port_candidates_pd = port_candidates.toPandas()\n",
    "    else:\n",
    "        port_candidates_pd = port_candidates\n",
    "\n",
    "    # Zoom into Denmark\n",
    "    mean_lat = port_candidates_pd[\"lat_bin\"].mean()\n",
    "    mean_lon = port_candidates_pd[\"lon_bin\"].mean()\n",
    "    m = folium.Map(location=[mean_lat, mean_lon], zoom_start=7)\n",
    "    \n",
    "    # Visualize the ports as circles\n",
    "    for _, row in port_candidates_pd.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"lat_bin\"], row[\"lon_bin\"]],\n",
    "            radius=min(row[\"vessel_count\"], 20), \n",
    "            color=\"blue\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"Vessels: {row['vessel_count']}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    m.save(f\"{map_name}.html\")\n",
    "\n",
    "visualize_ports(port_candidates, \"binning_ports\")\n",
    "visualize_ports(port_candidates_agg, \"binning_ports_agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d61551f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ports(ports_clusters, map_name='dbscan_ports', to_pandas=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
